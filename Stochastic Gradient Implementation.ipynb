{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "# import catboost\n",
    "# from catboost import CatBoostClassifier\n",
    "# import rb\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'neutral'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Corpus = pd.read_csv(r\"data/student_evaluation.csv\",encoding='latin-1')\n",
    "# Corpus.head()\n",
    "Corpus.Sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Great.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I do not know how this course is going to help...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all is Perfect.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>could be more interactive and practical with l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>More examples required to get a better grip on...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  Sentiment  Actual\n",
       "0                                             Great.        NaN       1\n",
       "1  I do not know how this course is going to help...        NaN       0\n",
       "2                                    all is Perfect.        NaN       1\n",
       "3  could be more interactive and practical with l...        NaN       0\n",
       "4  More examples required to get a better grip on...        NaN       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(r\"data/test.csv\",encoding='latin-1')\n",
    "test.head()\n",
    "# Corpus.Sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step - a : Remove blank rows if any.\n",
    "test['comment'].dropna(inplace=True)\n",
    "\n",
    "# Step - b : Change all the text to lower case. This is required as python interprets 'dog' and 'DOG' differently\n",
    "test['comment'] = [entry.lower() for entry in test['comment']]\n",
    "\n",
    "# Step - c : Tokenization : In this each entry in the test will be broken into set of words\n",
    "test['comment']= [word_tokenize(entry) for entry in test['comment']]\n",
    "\n",
    "# Step - d : Remove Stop words, Non-Numeric and perfom Word Stemming/Lemmenting.\n",
    "# WordNetLemmatizer requires Pos tags to understand if the word is noun or verb or adjective etc. By default it is set to Noun\n",
    "tag_map = defaultdict(lambda : wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "for index,entry in enumerate(test['comment']):\n",
    "    # Declaring Empty List to store the words that follow the rules for this step\n",
    "    final_words = []\n",
    "    # Initializing WordNetLemmatizer()\n",
    "    word_Lemmatized = WordNetLemmatizer()\n",
    "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
    "    for word, tag in pos_tag(entry):\n",
    "        # Below condition is to check for Stop words and consider only alphabets\n",
    "        if word not in stopwords.words('english') and word.isalpha():\n",
    "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
    "            final_words.append(word_Final)\n",
    "    # The final processed set of words for each iteration will be stored in 'text_final'\n",
    "    test.loc[index,'test_final'] = str(final_words)\n",
    "\n",
    "# print(Final_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step - a : Remove blank rows if any.\n",
    "Corpus['comment'].dropna(inplace=True)\n",
    "\n",
    "# Step - b : Change all the text to lower case. This is required as python interprets 'dog' and 'DOG' differently\n",
    "Corpus['comment'] = [entry.lower() for entry in Corpus['comment']]\n",
    "\n",
    "# Step - c : Tokenization : In this each entry in the corpus will be broken into set of words\n",
    "Corpus['comment']= [word_tokenize(entry) for entry in Corpus['comment']]\n",
    "\n",
    "# Step - d : Remove Stop words, Non-Numeric and perfom Word Stemming/Lemmenting.\n",
    "# WordNetLemmatizer requires Pos tags to understand if the word is noun or verb or adjective etc. By default it is set to Noun\n",
    "tag_map = defaultdict(lambda : wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "for index,entry in enumerate(Corpus['comment']):\n",
    "    # Declaring Empty List to store the words that follow the rules for this step\n",
    "    Final_words = []\n",
    "    # Initializing WordNetLemmatizer()\n",
    "    word_Lemmatized = WordNetLemmatizer()\n",
    "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
    "    for word, tag in pos_tag(entry):\n",
    "        # Below condition is to check for Stop words and consider only alphabets\n",
    "        if word not in stopwords.words('english') and word.isalpha():\n",
    "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
    "            Final_words.append(word_Final)\n",
    "    # The final processed set of words for each iteration will be stored in 'text_final'\n",
    "    Corpus.loc[index,'text_final'] = str(Final_words)\n",
    "\n",
    "# print(Final_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     335\n",
       "positive    306\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(Corpus['text_final'],Corpus['Sentiment'],test_size=0.2)\n",
    "X_Test= test['test_final']\n",
    "Corpus['Sentiment'].value_counts()\n",
    "# Corpus['text_final']\n",
    "# X_Test.shape()\n",
    "# Train_X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder = LabelEncoder()\n",
    "Train_Y = Encoder.fit_transform(Train_Y)\n",
    "Test_Y = Encoder.fit_transform(Test_Y)\n",
    "# Test_X.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfidf_vect = TfidfVectorizer()\n",
    "Tfidf_vect.fit(Corpus['text_final'])\n",
    "Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
    "Test_X_Tfidf = Tfidf_vect.transform(Test_X)\n",
    "# type(Test_X_Tfidf)\n",
    "# print(Train_X_Tfidf)\n",
    "# vectorizer = CountVectorizer(ngram_range=(2,2))\n",
    "# Tfidf_vect.fit_transform(Corpus['text_final'])\n",
    "\n",
    "# print(Tfidf_vect.get_feature_names())\n",
    "\n",
    "# vectorizer = TfidfVectorizer(ngram_range=(2,2)) # You can still specify n-grams here.\n",
    "# X = vectorizer.fit_transform(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Train_X_Tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7286821705426356"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "#pipeline model SGD\n",
    "text_clf_sgd= Pipeline([('vect', TfidfVectorizer(ngram_range=(1,1))), \n",
    "                      ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                    alpha=1e-3, random_state=42,\n",
    "                    max_iter=5, tol=None)) ])\n",
    "# train the model\n",
    "text_clf_sgd.fit(Train_X,Train_Y)\n",
    "predicted_sgd = text_clf_sgd.predict(Test_X)\n",
    "np.mean(predicted_sgd == Test_Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix \n",
      " [[46 16]\n",
      " [19 48]]\n",
      "\n",
      " Classification report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.74      0.72        62\n",
      "          1       0.75      0.72      0.73        67\n",
      "\n",
      "avg / total       0.73      0.73      0.73       129\n",
      "\n",
      "\n",
      " SGDboost accuracy score -- >  72.86821705426357\n",
      "\n",
      " SGDboost precision score -- >  72.96660703637447\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix_result = confusion_matrix(Test_Y, predicted_sgd)\n",
    "print(\"Confusion matrix \\n\",confusion_matrix_result)\n",
    "print(\"\\n Classification report \\n\",classification_report(Test_Y, predicted_sgd))\n",
    "print(\"\\n SGDboost accuracy score -- > \",accuracy_score(Test_Y,predicted_sgd)*100) \n",
    "print(\"\\n SGDboost precision score -- > \",precision_score(Test_Y,predicted_sgd, average = 'weighted')*100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the predictions with trained model and submit the predictions.\n",
    "# y_pred=model.predict_classes(X_test)\n",
    "\n",
    "predictions_Test_SGD = text_clf_sgd.predict(X_Test)\n",
    "\n",
    "test['Sentiment'] = predictions_Test_SGD\n",
    "submission = test[[\"comment\",\"Sentiment\",\"Actual\"]]\n",
    "submission.to_csv(\"data/results/SGD_submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import SGDClassifier\n",
    "# sgd = SGDClassifier(loss='hinge', penalty='l2',\n",
    "#                     alpha=1e-3, random_state=42,\n",
    "#                     max_iter=5, tol=None)\n",
    "# sgd.fit(Train_X_Tfidf,Train_Y)\n",
    "# sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make predictions for test data\n",
    "# y_pred = sgd.predict(Test_X_Tfidf)\n",
    "# predictions_sgd = [round(value) for value in y_pred]\n",
    "\n",
    "# # evaluate predictions\n",
    "# # print(\"sgd Accuracy Score -> \",accuracy_score(prediction_sgd, Test_Y)*100)\n",
    "\n",
    "# confusion_matrix_result = confusion_matrix(Test_Y, predictions_sgd)\n",
    "# print(\"Confusion matrix \\n\",confusion_matrix_result)\n",
    "# print(\"\\n Classification report \\n\",classification_report(Test_Y, predictions_sgd))\n",
    "# print(\"\\n sgd accuracy score -- > \",accuracy_score(Test_Y, predictions_sgd)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes = [\"No\", \"Yes\"]\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(confusion_matrix_result, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "# plt.title(\"Confusion Matrix - Text Clasiffication\")\n",
    "# plt.colorbar()\n",
    "# tick_marks = np.arange(len(classes))\n",
    "# plt.xticks(tick_marks, classes, rotation=45)\n",
    "# plt.yticks(tick_marks, classes)\n",
    "\n",
    "# text_format = 'd'\n",
    "# thresh = confusion_matrix_result.max() / 2.\n",
    "# for row, column in itertools.product(range(confusion_matrix_result.shape[0]), range(confusion_matrix_result.shape[1])):\n",
    "#     plt.text(column, row, format(confusion_matrix_result[row, column], text_format),\n",
    "#              horizontalalignment=\"center\",\n",
    "#              color=\"white\" if confusion_matrix_result[row, column] > thresh else \"black\")\n",
    "\n",
    "# plt.ylabel('True label')\n",
    "# plt.xlabel('Predicted label')\n",
    "# plt.tight_layout()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
