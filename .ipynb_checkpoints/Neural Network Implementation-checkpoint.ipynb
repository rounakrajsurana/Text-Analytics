{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/@bedigunjit/simple-guide-to-text-classification-nlp-using-svm-and-naive-bayes-with-python-421db3a72d34\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "# import catboost\n",
    "# from catboost import CatBoostClassifier\n",
    "# import rb\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'neutral'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Corpus = pd.read_csv(r\"data/student_evaluation.csv\",encoding='latin-1')\n",
    "# Corpus.head()\n",
    "Corpus.Sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Great.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I do not know how this course is going to help...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all is Perfect.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>could be more interactive and practical with l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>More examples required to get a better grip on...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  Sentiment  Actual\n",
       "0                                             Great.        NaN       1\n",
       "1  I do not know how this course is going to help...        NaN       0\n",
       "2                                    all is Perfect.        NaN       1\n",
       "3  could be more interactive and practical with l...        NaN       0\n",
       "4  More examples required to get a better grip on...        NaN       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(r\"data/test.csv\",encoding='latin-1')\n",
    "test.head()\n",
    "# Corpus.Sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step - a : Remove blank rows if any.\n",
    "test['comment'].dropna(inplace=True)\n",
    "\n",
    "# Step - b : Change all the text to lower case. This is required as python interprets 'dog' and 'DOG' differently\n",
    "test['comment'] = [entry.lower() for entry in test['comment']]\n",
    "\n",
    "# Step - c : Tokenization : In this each entry in the test will be broken into set of words\n",
    "test['comment']= [word_tokenize(entry) for entry in test['comment']]\n",
    "\n",
    "# Step - d : Remove Stop words, Non-Numeric and perfom Word Stemming/Lemmenting.\n",
    "# WordNetLemmatizer requires Pos tags to understand if the word is noun or verb or adjective etc. By default it is set to Noun\n",
    "tag_map = defaultdict(lambda : wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "for index,entry in enumerate(test['comment']):\n",
    "    # Declaring Empty List to store the words that follow the rules for this step\n",
    "    final_words = []\n",
    "    # Initializing WordNetLemmatizer()\n",
    "    word_Lemmatized = WordNetLemmatizer()\n",
    "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
    "    for word, tag in pos_tag(entry):\n",
    "        # Below condition is to check for Stop words and consider only alphabets\n",
    "        if word not in stopwords.words('english') and word.isalpha():\n",
    "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
    "            final_words.append(word_Final)\n",
    "    # The final processed set of words for each iteration will be stored in 'text_final'\n",
    "    test.loc[index,'test_final'] = str(final_words)\n",
    "\n",
    "# print(Final_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step - a : Remove blank rows if any.\n",
    "Corpus['comment'].dropna(inplace=True)\n",
    "\n",
    "# Step - b : Change all the text to lower case. This is required as python interprets 'dog' and 'DOG' differently\n",
    "Corpus['comment'] = [entry.lower() for entry in Corpus['comment']]\n",
    "\n",
    "# Step - c : Tokenization : In this each entry in the corpus will be broken into set of words\n",
    "Corpus['comment']= [word_tokenize(entry) for entry in Corpus['comment']]\n",
    "\n",
    "# Step - d : Remove Stop words, Non-Numeric and perfom Word Stemming/Lemmenting.\n",
    "# WordNetLemmatizer requires Pos tags to understand if the word is noun or verb or adjective etc. By default it is set to Noun\n",
    "tag_map = defaultdict(lambda : wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "for index,entry in enumerate(Corpus['comment']):\n",
    "    # Declaring Empty List to store the words that follow the rules for this step\n",
    "    Final_words = []\n",
    "    # Initializing WordNetLemmatizer()\n",
    "    word_Lemmatized = WordNetLemmatizer()\n",
    "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
    "    for word, tag in pos_tag(entry):\n",
    "        # Below condition is to check for Stop words and consider only alphabets\n",
    "        if word not in stopwords.words('english') and word.isalpha():\n",
    "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
    "            Final_words.append(word_Final)\n",
    "    # The final processed set of words for each iteration will be stored in 'text_final'\n",
    "    Corpus.loc[index,'text_final'] = str(Final_words)\n",
    "\n",
    "# print(Final_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     335\n",
       "positive    306\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(Corpus['text_final'],Corpus['Sentiment'],test_size=0.2)\n",
    "X_Test= test['test_final']\n",
    "Corpus['Sentiment'].value_counts()\n",
    "# Corpus['text_final']\n",
    "# X_Test.shape()\n",
    "# Train_X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(Corpus['text_final'],Corpus['suggestion'],test_size=0.2)\n",
    "# # Train_X\n",
    "# # Test_Y.describe()\n",
    "# # type(Test_Y)\n",
    "# a = Corpus.to_numpy()\n",
    "# # a = Train_X.to_numpy()\n",
    "# a.shape\n",
    "# nos = a[a=='NO']\n",
    "# CS = a[a == 'CS']\n",
    "# IS = a[a == 'IS']\n",
    "\n",
    "# print(nos.shape)\n",
    "# print(CS.shape)\n",
    "\n",
    "# print(IS.shape)\n",
    "# # yes = a[a=='yes']\n",
    "# # yes.shape\n",
    "# # Test_Y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder = LabelEncoder()\n",
    "Train_Y = Encoder.fit_transform(Train_Y)\n",
    "Test_Y = Encoder.fit_transform(Test_Y)\n",
    "# Test_X.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfidf_vect = TfidfVectorizer()\n",
    "Tfidf_vect.fit(Corpus['text_final'])\n",
    "Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
    "Test_X_Tfidf = Tfidf_vect.transform(Test_X)\n",
    "# type(Test_X_Tfidf)\n",
    "# print(Train_X_Tfidf)\n",
    "# vectorizer = CountVectorizer(ngram_range=(2,2))\n",
    "# Tfidf_vect.fit_transform(Corpus['text_final'])\n",
    "\n",
    "# print(Tfidf_vect.get_feature_names())\n",
    "\n",
    "# vectorizer = TfidfVectorizer(ngram_range=(2,2)) # You can still specify n-grams here.\n",
    "# X = vectorizer.fit_transform(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Train_X_Tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree CART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_clf_DT = Pipeline([('vect', TfidfVectorizer(ngram_range=(1,1))), \n",
    "                      ('clf', DecisionTreeClassifier()) ])\n",
    "text_clf_DT.fit(Train_X,Train_Y)\n",
    "\n",
    "predictions_DT = text_clf_DT.predict(Test_X)\n",
    "\n",
    "# print(text_clf_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Classification report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.71      0.72        62\n",
      "          1       0.74      0.75      0.74        67\n",
      "\n",
      "avg / total       0.73      0.73      0.73       129\n",
      "\n",
      "\n",
      " Decision Tree accuracy score -- >  72.86821705426357\n",
      "\n",
      " Decision Tree precision score -- >  72.85737779671533\n"
     ]
    }
   ],
   "source": [
    "# confusion_matrix_result = confusion_matrix(Test_Y, predictions_DT)\n",
    "# print(\"Confusion matrix \\n\",confusion_matrix_result)\n",
    "print(\"\\n Classification report \\n\",classification_report(Test_Y, predictions_DT))\n",
    "print(\"\\n Decision Tree accuracy score -- > \",accuracy_score(Test_Y, predictions_DT)*100)  \n",
    "\n",
    "print(\"\\n Decision Tree precision score -- > \",precision_score(Test_Y, predictions_DT, average = 'weighted')*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pipeline model \n",
    "\n",
    "text_clf = Pipeline([('vect', TfidfVectorizer()), \n",
    "                      ('clf', MultinomialNB()) ])\n",
    "text_clf.fit(Train_X,Train_Y)\n",
    "\n",
    "predictions_NB = text_clf.predict(Test_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the predictions with trained model and submit the predictions.\n",
    "# y_pred=model.predict_classes(X_test)\n",
    "\n",
    "predictions_Test_NB = text_clf.predict(X_Test)\n",
    "\n",
    "test['Sentiment'] = predictions_Test_NB\n",
    "submission = test[[\"comment\",\"Sentiment\"]]\n",
    "submission.to_csv(\"data/Finalsubmission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = np.round(np.argmax(pred, axis=1)).astype(int)\n",
    "# sub['Sentiment'] = predictions\n",
    "# sub.to_csv(\"blend.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #make the predictions with trained model and submit the predictions.\n",
    "# # y_pred=model.predict_classes(X_test)\n",
    "# predictions_Test_NB = text_clf.predict(X_Test)\n",
    "\n",
    "# sub_file = pd.read_csv('data/test.csv',sep=',')\n",
    "# sub_file.Sentiment=predictions_Test_NB\n",
    "# sub_file.to_csv('Submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_result = confusion_matrix(Test_Y, predictions_NB)\n",
    "print(\"Confusion matrix \\n\",confusion_matrix_result)\n",
    "print(\"\\n Classification report \\n\",classification_report(Test_Y, predictions_NB))\n",
    "print(\"\\n Naive Bayes accuracy score -- > \",accuracy_score(Test_Y, predictions_NB)*100)  \n",
    "\n",
    "print(\"\\n Naive Bayes precision score -- > \",precision_score(Test_Y, predictions_NB, average = 'weighted')*100)  \n",
    "#make the predictions with trained model and submit the predictions.\n",
    "# # y_pred=model.predict_classes(X_test)\n",
    "# predictions_Test_NB = text_clf.predict(X_Test)\n",
    "\n",
    "# sub_file = pd.read_csv('data/test.csv',sep=',')\n",
    "# sub_file.Sentiment=predictions_Test_NB\n",
    "# sub_file.to_csv('Submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline shortens the steps \n",
    "# https://www.youtube.com/watch?v=0kPRaYSgblM\n",
    "# https://github.com/codewrestling/TextClassification/blob/master/Text%20Classification.py\n",
    "\n",
    "text_clf = Pipeline([('vect', TfidfVectorizer()), \n",
    "                      ('clf', MultinomialNB()) ])\n",
    "# train the model\n",
    "text_clf.fit(Train_X,Train_Y)\n",
    "\n",
    "# Predict the test cases\n",
    "test_x = ['Few more application specific contents is needed. ','Good course.', 'Please include Field trips.','I think an in class mini-project should be considered to be done step by step in during lectures.']\n",
    "# test_x = [input()]\n",
    "predicted = text_clf.predict(test_x)\n",
    "for x in predicted:\n",
    "    print(x)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the training dataset on the NB classifier\n",
    "Naive = naive_bayes.MultinomialNB()\n",
    "Naive.fit(Train_X_Tfidf,Train_Y)\n",
    "\n",
    "\n",
    "# docs = ['Also the project helped us implement real world applications that is further helpful if we plan to do research in this field.']\n",
    "docs = ['not at all satisfied','Good course.', 'Please include Field trips.','I think an in class mini-project should be considered to be done step by step in during lectures.']\n",
    "\n",
    "# docs = [input()]\n",
    "# docs = input()\n",
    "x_new_tfidf = Tfidf_vect.transform(docs)\n",
    "predictions = Naive.predict(x_new_tfidf)\n",
    "\n",
    "for x in predictions:\n",
    "    print(x)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the training dataset on the NB classifier\n",
    "Naive = naive_bayes.MultinomialNB()\n",
    "Naive.fit(Train_X_Tfidf,Train_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the labels on validation dataset\n",
    "from sklearn.metrics import f1_score \n",
    "predicted_NB = Naive.predict(Test_X_Tfidf)\n",
    "\n",
    "confusion_matrix_result = confusion_matrix(Test_Y, predicted_NB)\n",
    "print(\"Confusion matrix \\n\",confusion_matrix_result)\n",
    "print(\"\\n Classification report \\n\",classification_report(Test_Y, predicted_NB))\n",
    "print(\"\\n Naive Bayes accuracy score -- > \",accuracy_score(Test_Y, predicted_NB)*100)  \n",
    "\n",
    "print(\"\\n Naive Bayes precision score -- > \",precision_score(Test_Y, predicted_NB, average = 'weighted')*100)  \n",
    "\n",
    "print(\"\\n Naive Bayes recall score -- > \",recall_score(Test_Y, predicted_NB, average = 'weighted')*100)  \n",
    "\n",
    "print(\"\\n Naive Bayes f1_score -- > \",f1_score(Test_Y, predicted_NB, average = 'weighted')*100)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #make the predictions with trained model and submit the predictions.\n",
    "# y_pred=model.predict_classes(X_test)\n",
    "\n",
    "# sub_file = pd.read_csv('../input/sampleSubmission.csv',sep=',')\n",
    "# sub_file.Sentiment=y_pred\n",
    "# sub_file.to_csv('Submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_NB = confusion_matrix(Test_Y, predictions_NB)\n",
    "\n",
    "classes = [\"Positive\",\"Neutral\"]\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(confusion_matrix_NB, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix - Text Clasiffication\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "text_format = 'd'\n",
    "thresh = confusion_matrix_NB.max() / 2.\n",
    "for row, column in itertools.product(range(confusion_matrix_NB.shape[0]), range(confusion_matrix_NB.shape[1])):\n",
    "    plt.text(column, row, format(confusion_matrix_NB[row, column], text_format),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if confusion_matrix_NB[row, column] > thresh else \"black\")\n",
    "\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Train_Y)\n",
    "len(Test_Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fit the training dataset on the NB classifier\n",
    "BNaive = naive_bayes.BernoulliNB()\n",
    "BNaive.fit(Train_X_Tfidf,Train_Y)\n",
    "# predict the labels on validation dataset\n",
    "Bpredictions_NB = BNaive.predict(Test_X_Tfidf)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(Bpredictions_NB, Test_Y)*100)\n",
    "print(\"Naive Bayes precision Score -> \",precision_score(Bpredictions_NB, Test_Y, average = 'weighted')*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline model \n",
    "\n",
    "text_clf_BNB = Pipeline([('vect', TfidfVectorizer()), \n",
    "                      ('clf', BernoulliNB()) ])\n",
    "text_clf_BNB.fit(Train_X,Train_Y)\n",
    "\n",
    "Bepredictions_NB = text_clf_BNB.predict(Test_X)\n",
    "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(Bepredictions_NB, Test_Y)*100)\n",
    "\n",
    "print(\"Naive Bayes precision Score -> \",precision_score(Bepredictions_NB, Test_Y, average = 'weighted')*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the predictions with trained model and submit the predictions.\n",
    "# y_pred=model.predict_classes(X_test)\n",
    "\n",
    "# predictions_Test_NB = text_clf.predict(X_Test)\n",
    "\n",
    "Bepredictions_NB = text_clf_BNB.predict(X_Test)\n",
    "\n",
    "test['Sentiment'] = Bepredictions_NB\n",
    "submission = test[[\"comment\",\"Sentiment\"]]\n",
    "submission.to_csv(\"data/submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score ->  74.4186046511628\n"
     ]
    }
   ],
   "source": [
    "# Classifier - Algorithm - SVM\n",
    "\n",
    "# fit the training dataset on the classifier\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(Train_X_Tfidf,Train_Y)\n",
    "# predict the labels on validation dataset\n",
    "predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, Test_Y)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# parameters_svm = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "#              'tfidf__use_idf': (True, False),\n",
    "#              'clf-svm__alpha': (1e-2, 1e-3),\n",
    "# }\n",
    "# gs_clf_svm = GridSearchCV(text_clf_SVM, parameters_svm, n_jobs=-1)\n",
    "# gs_clf_svm = gs_clf_svm.fit(Train_X,Train_Y)\n",
    "# gs_clf_svm.best_score_\n",
    "# gs_clf_svm.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score ->  73.64341085271317\n"
     ]
    }
   ],
   "source": [
    "#pipeline model SVM\n",
    "text_clf_SVM= Pipeline([('vect', TfidfVectorizer(ngram_range=(1,1))), \n",
    "                      ('clf', SVC(C=1.0, kernel='linear', degree=3, gamma='auto')) ])\n",
    "# train the model\n",
    "text_clf_SVM.fit(Train_X,Train_Y)\n",
    "predicted_svm = text_clf_SVM.predict(Test_X)\n",
    "np.mean(predicted_svm == Test_Y)\n",
    "\n",
    "# Predict the test cases\n",
    "# test_x = [input()]\n",
    "# test_x = ['Also the project helped us implement real world applications that is further helpful if we plan to do research in this field.']\n",
    "# test_x = ['Decision Support Technologies is a required course of IM course. ','no.', 'Please include Field trips.','I think an in class mini-project should be considered to be done step by step in during lectures.']\n",
    "# test_x = ['Few more application specific contents is needed. ','Good course.', 'Please include Field trips.','I think an in class mini-project should be considered to be done step by step in during lectures.']\n",
    "\n",
    "# predicted_svm = text_clf_SVM.predict(Test_Y)\n",
    "# for x in predicted_svm:\n",
    "#     print(x)\n",
    "\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(predicted_svm, Test_Y)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
    "confusion_matrix_result = confusion_matrix(Test_Y, predicted_svm)\n",
    "print(\"Confusion matrix \\n\",confusion_matrix_result)\n",
    "print(\"\\n Classification report \\n\",classification_report(Test_Y, predicted_svm))\n",
    "\n",
    "print(\"\\n SVM accuracy score -- > \",accuracy_score(Test_Y, predicted_svm)*100) \n",
    "print(\"\\n SVM precision score -- > \",precision_score(Test_Y, predicted_svm, average = 'weighted')*100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"IS\",\"CS\", \"neutral\",\"positive\"]\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(confusion_matrix_result, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix - Text Clasiffication\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "text_format = 'd'\n",
    "thresh = confusion_matrix_result.max() / 2.\n",
    "for row, column in itertools.product(range(confusion_matrix_result.shape[0]), range(confusion_matrix_result.shape[1])):\n",
    "    plt.text(column, row, format(confusion_matrix_result[row, column], text_format),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if confusion_matrix_result[row, column] > thresh else \"black\")\n",
    "\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# parameters_svm = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "#              'tfidf__use_idf': (True, False),\n",
    "#              'clf-svm__alpha': (1e-2, 1e-3),\n",
    "# }\n",
    "# gs_clf_svm = GridSearchCV(text_clf_SVM, parameters_svm, n_jobs=-1)\n",
    "# gs_clf_svm = gs_clf_svm.fit(Train_X_Tfidf,Train_Y)\n",
    "# gs_clf_svm.best_score_\n",
    "# # gs_clf_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "# https://stackabuse.com/text-classification-with-python-and-scikit-learn/\n",
    "with open('text_classifier', 'wb') as picklefile:\n",
    "    pickle.dump(SVM,picklefile)\n",
    "\n",
    "# to load the model use the following\n",
    "with open('text_classifier', 'rb') as training_model:\n",
    "    model = pickle.load(training_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the training dataset on the classifier\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(Train_X_Tfidf,Train_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
    "\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, Test_Y)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
    "confusion_matrix_result = confusion_matrix(Test_Y, predictions_SVM)\n",
    "print(\"Confusion matrix \\n\",confusion_matrix_result)\n",
    "print(\"\\n Classification report \\n\",classification_report(Test_Y, predictions_SVM))\n",
    "print(\"\\n SVM precision score -- > \",precision_score(Test_Y, predictions_SVM, average = 'weighted')*100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"suggestion\", \"neutral\",\"positive\"]\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(confusion_matrix_result, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix - Text Clasiffication\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "text_format = 'd'\n",
    "thresh = confusion_matrix_result.max() / 2.\n",
    "for row, column in itertools.product(range(confusion_matrix_result.shape[0]), range(confusion_matrix_result.shape[1])):\n",
    "    plt.text(column, row, format(confusion_matrix_result[row, column], text_format),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if confusion_matrix_result[row, column] > thresh else \"black\")\n",
    "\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier - Algorithm - SVM\n",
    "# fit the training dataset on the classifier\n",
    "SVM = svm.SVC(C=1.0, kernel='rbf', degree=3, gamma='auto')\n",
    "SVM.fit(Train_X_Tfidf,Train_Y)\n",
    "# predict the labels on validation dataset\n",
    "predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, Test_Y)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(learning_rate=0.01)\n",
    "xgb.fit(Train_X_Tfidf,Train_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline model XGB\n",
    "text_clf_XGB= Pipeline([('vect', TfidfVectorizer(ngram_range=(1,1))), \n",
    "                      ('clf', XGBClassifier(learning_rate=0.01)) ])\n",
    "# train the model\n",
    "text_clf_XGB.fit(Train_X,Train_Y)\n",
    "predicted_XGB = text_clf_XGB.predict(Test_X)\n",
    "# np.mean(predicted_XGB == Test_Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_result = confusion_matrix(Test_Y, predicted_XGB)\n",
    "print(\"Confusion matrix \\n\",confusion_matrix_result)\n",
    "print(\"\\n Classification report \\n\",classification_report(Test_Y, predicted_XGB))\n",
    "\n",
    "print(\"\\n XGBboost accuracy score -- > \",accuracy_score(Test_Y,predicted_XGB)*100)\n",
    "print(\"\\n XGBoost precision score -- > \",precision_score(Test_Y, predicted_XGB, average = 'weighted')*100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for test data\n",
    "y_pred = xgb.predict(Test_X_Tfidf)\n",
    "predictions_xgboost = [round(value) for value in y_pred]\n",
    "\n",
    "# evaluate predictions\n",
    "print(\"xgboost Accuracy Score -> \",accuracy_score(predictions_xgboost, Test_Y)*100)\n",
    "\n",
    "confusion_matrix_result = confusion_matrix(Test_Y, predictions_xgboost)\n",
    "print(\"Confusion matrix \\n\",confusion_matrix_result)\n",
    "print(\"\\n Classification report \\n\",classification_report(Test_Y, predictions_xgboost))\n",
    "print(\"\\n xgboost accuracy score -- > \",accuracy_score(Test_Y, predictions_xgboost)*100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"No\", \"Yes\"]\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(confusion_matrix_result, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix - Text Clasiffication\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "text_format = 'd'\n",
    "thresh = confusion_matrix_result.max() / 2.\n",
    "for row, column in itertools.product(range(confusion_matrix_result.shape[0]), range(confusion_matrix_result.shape[1])):\n",
    "    plt.text(column, row, format(confusion_matrix_result[row, column], text_format),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if confusion_matrix_result[row, column] > thresh else \"black\")\n",
    "\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf_XGB= Pipeline([('vect', TfidfVectorizer()), \n",
    "                      ('clf', XGBClassifier()) ])\n",
    "# train the model\n",
    "text_clf_XGB.fit(Train_X,Train_Y)\n",
    "\n",
    "# Predict the test cases\n",
    "# test_x = ['Few more application specific contents is needed. ','Good course.', 'Please include Field trips.','I think an in class mini-project should be considered to be done step by step in during lectures.']\n",
    "test_x = [input()]\n",
    "\n",
    "predicted_XGB = text_clf_XGB.predict(test_x)\n",
    "for x in predicted_XGB:\n",
    "    print(x)\n",
    "\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(predicted_svm, Test_Y)*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "#pipeline model SGD\n",
    "text_clf_sgd= Pipeline([('vect', TfidfVectorizer(ngram_range=(1,1))), \n",
    "                      ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                    alpha=1e-3, random_state=42,\n",
    "                    max_iter=5, tol=None)) ])\n",
    "# train the model\n",
    "text_clf_sgd.fit(Train_X,Train_Y)\n",
    "predicted_sgd = text_clf_sgd.predict(Test_X)\n",
    "np.mean(predicted_sgd == Test_Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_result = confusion_matrix(Test_Y, predicted_sgd)\n",
    "print(\"Confusion matrix \\n\",confusion_matrix_result)\n",
    "print(\"\\n Classification report \\n\",classification_report(Test_Y, predicted_sgd))\n",
    "print(\"\\n SGDboost accuracy score -- > \",accuracy_score(Test_Y,predicted_sgd)*100) \n",
    "print(\"\\n SGDboost precision score -- > \",precision_score(Test_Y,predicted_sgd, average = 'weighted')*100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd = SGDClassifier(loss='hinge', penalty='l2',\n",
    "                    alpha=1e-3, random_state=42,\n",
    "                    max_iter=5, tol=None)\n",
    "sgd.fit(Train_X_Tfidf,Train_Y)\n",
    "sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for test data\n",
    "y_pred = sgd.predict(Test_X_Tfidf)\n",
    "predictions_sgd = [round(value) for value in y_pred]\n",
    "\n",
    "# evaluate predictions\n",
    "# print(\"sgd Accuracy Score -> \",accuracy_score(prediction_sgd, Test_Y)*100)\n",
    "\n",
    "confusion_matrix_result = confusion_matrix(Test_Y, predictions_sgd)\n",
    "print(\"Confusion matrix \\n\",confusion_matrix_result)\n",
    "print(\"\\n Classification report \\n\",classification_report(Test_Y, predictions_sgd))\n",
    "print(\"\\n sgd accuracy score -- > \",accuracy_score(Test_Y, predictions_sgd)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"No\", \"Yes\"]\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(confusion_matrix_result, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix - Text Clasiffication\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "text_format = 'd'\n",
    "thresh = confusion_matrix_result.max() / 2.\n",
    "for row, column in itertools.product(range(confusion_matrix_result.shape[0]), range(confusion_matrix_result.shape[1])):\n",
    "    plt.text(column, row, format(confusion_matrix_result[row, column], text_format),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if confusion_matrix_result[row, column] > thresh else \"black\")\n",
    "\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SGD classifier\n",
    "# # https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "# # text_clf_sgd = Pipeline([('tfidf', TfidfVectorizer()), \n",
    "# #                      ('clf', SGDClassifier(loss='hinge', penalty='l2', \n",
    "# #                                            alpha=1e-3, random_state=42,\n",
    "# #                                            max_iter=5, tol=None)),])\n",
    "\n",
    "\n",
    "# sgd = SGDClassifier(loss='hinge', penalty='l2',\n",
    "#                     alpha=1e-3, random_state=42,\n",
    "#                     max_iter=5, tol=None)\n",
    "# sgd.fit(Train_X_Tfidf,Train_Y)\n",
    "\n",
    "\n",
    "# # make predictions for test data\n",
    "# y_pred = sgd.predict(Test_X_Tfidf)\n",
    "# prediction_sgd = [round(value) for value in y_pred]\n",
    "\n",
    "# # evaluate predictions\n",
    "# # print(\"sgd Accuracy Score -> \",accuracy_score(prediction_sgd, Test_Y)*100)\n",
    "\n",
    "# confusion_matrix_result = confusion_matrix(Test_Y, predictions_sgd)\n",
    "# print(\"Confusion matrix \\n\",confusion_matrix_result)\n",
    "# print(\"\\n Classification report \\n\",classification_report(Test_Y, predictions_sgd))\n",
    "# print(\"\\n sgd accuracy score -- > \",accuracy_score(Test_Y, predictions_sgd)*100)\n",
    "\n",
    "# # text_clf_sgd.fit(Train_X,Train_Y)  \n",
    "# # # Pipeline(...)\n",
    "# # test_x = [(input())]\n",
    "# # predicted_sgd = text_clf_sgd.predict(test_x)\n",
    "# # for x in predicted_sgd:\n",
    "# #     print(x)\n",
    "# # # np.mean(predicted == Test_Y)            \n",
    "# # # 0.9101..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 20)                15380     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 15,401\n",
      "Trainable params: 15,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training Accuracy: 0.9824\n",
      "Testing Accuracy:  0.6977\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "\n",
    "input_dim = Train_X_Tfidf.shape[1]  # Number of features\n",
    "print(input_dim)\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(20, input_dim=input_dim, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# xgb.fit(Train_X_Tfidf,Train_Y)\n",
    "history = model.fit(Train_X_Tfidf,Train_Y,\n",
    "                    epochs=100,\n",
    "                    verbose=False,\n",
    "                    validation_data=(Test_X_Tfidf, Test_Y),\n",
    "                    batch_size=10)\n",
    "\n",
    "loss, accuracy = model.evaluate(Train_X_Tfidf,Train_Y, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy= model.evaluate(Test_X_Tfidf, Test_Y, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_dim = Train_X_Tfidf.shape[0]  # Number of features\n",
    "print(input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # # First XGBoost model for Pima Indians dataset\n",
    "# # from numpy import loadtxt\n",
    "# # from xgboost import XGBClassifier\n",
    "# # from sklearn.model_selection import train_test_split\n",
    "# # from sklearn.metrics import accuracy_score\n",
    "# # # load data\n",
    "# # dataset = loadtxt('pima-indians-diabetes.csv', delimiter=\",\")\n",
    "# # # split data into X and y\n",
    "# # X = dataset[:,0:8]\n",
    "# # Y = dataset[:,8]\n",
    "# # # split data into train and test sets\n",
    "# # seed = 7\n",
    "# # test_size = 0.33\n",
    "# # X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "# # # fit model no training data\n",
    "# model = XGBClassifier()\n",
    "# model.fit(X_train, y_train)\n",
    "# # make predictions for test data\n",
    "# y_pred = model.predict(X_test)\n",
    "# predictions = [round(value) for value in y_pred]\n",
    "# # evaluate predictions\n",
    "# accuracy = accuracy_score(y_test, predictions)\n",
    "# print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(12,5))\n",
    "# sns.countplot(x=bbc_text_df.category, color='green')\n",
    "# plt.title('BBC text class distribution', fontsize=16)\n",
    "# plt.ylabel('Class Counts', fontsize=16)\n",
    "# plt.xlabel('Class Label', fontsize=16)\n",
    "# plt.xticks(rotation='vertical');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step - a : Remove blank rows if any.\n",
    "# Corpus['comment'].dropna(inplace=True)\n",
    "\n",
    "# # Step - b : Change all the text to lower case. This is required as python interprets 'dog' and 'DOG' differently\n",
    "# Corpus['comment'] = [entry.lower() for entry in Corpus['comment']]\n",
    "\n",
    "# # Step - c : Tokenization : In this each entry in the corpus will be broken into set of words\n",
    "# Corpus['comment']= [word_tokenize(entry) for entry in Corpus['comment']]\n",
    "\n",
    "# # Step - d : Remove Stop words, Non-Numeric and perfom Word Stemming/Lemmenting.\n",
    "# # WordNetLemmatizer requires Pos tags to understand if the word is noun or verb or adjective etc. By default it is set to Noun\n",
    "# tag_map = defaultdict(lambda : wn.NOUN)\n",
    "# tag_map['J'] = wn.ADJ\n",
    "# tag_map['V'] = wn.VERB\n",
    "# tag_map['R'] = wn.ADV\n",
    "# for index,entry in enumerate(Corpus['comment']):\n",
    "#     # Declaring Empty List to store the words that follow the rules for this step\n",
    "#     Final_words = []\n",
    "#     # Initializing WordNetLemmatizer()\n",
    "#     word_Lemmatized = WordNetLemmatizer()\n",
    "#     # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
    "#     for word, tag in pos_tag(entry):\n",
    "#         # Below condition is to check for Stop words and consider only alphabets\n",
    "#         if word not in stopwords.words('english') and word.isalpha():\n",
    "#             word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
    "#             Final_words.append(word_Final)\n",
    "#     # The final processed set of words for each iteration will be stored in 'text_final'\n",
    "#     Corpus.loc[index,'text_final'] = str(Final_words)\n",
    "# Final_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tkinter import *\n",
    " \n",
    "# window = Tk()\n",
    " \n",
    "# window.title(\"Welcome to LikeGeeks app\")\n",
    " \n",
    "# window.geometry('350x200')\n",
    " \n",
    "# lbl = Label(window, text=\"Hello\")\n",
    " \n",
    "# lbl.grid(column=0, row=0)\n",
    " \n",
    "# txt = Entry(window,width=10)\n",
    "# # txt.pack()\n",
    "# # txt.focus_set()\n",
    "# # insertedtext = txt.get()\n",
    "\n",
    "# txt.grid(column=1, row=0)\n",
    " \n",
    "# def clicked():\n",
    "#     text = txt.get()\n",
    "#     lower = text.lower()\n",
    "#     words= []\n",
    "#     remove_num = re.sub(r'\\d+', '', lower)\n",
    "#     print(remove_num,' \\n\\n')\n",
    "# # punch = remove_num.translate(string.maketrans(\"\",\"\"), string.punctuation)\n",
    "#     space = remove_num.strip()\n",
    "#     print(space,' \\n\\n')\n",
    "#     tokens = word_tokenize(space)\n",
    "#     print(tokens,' \\n\\n')\n",
    "#     stop_words = set(stopwords.words('english'))\n",
    "#     print(stop_words,' \\n\\n')\n",
    "#     result = [i for i in tokens if not i in stop_words]\n",
    "#     print(result,' \\n\\n')\n",
    "#     lemmatizer=WordNetLemmatizer()\n",
    "# #     l=lemmatizer.lemmatize([word for word in result])\n",
    "#     for word in result:\n",
    "#         words.append(lemmatizer.lemmatize(word))\n",
    "#     #Define class functions\n",
    "#     print(words,' \\n\\n')\n",
    "#     Test_X_Tfidf = Tfidf_vect.transform(words)\n",
    "# #      = txt.get()\n",
    "    \n",
    "#     out = model.predict(Test_X_Tfidflol)\n",
    "#     print(Test_X_Tfidflol)\n",
    "# #     print(out[1])\n",
    "    \n",
    "#     if out[0] == 0:\n",
    "#         lbl.configure(text=\"Suggestion is a NO\")\n",
    "#     else:\n",
    "#         lbl.configure(text=\"Suggestion is a YES\")\n",
    "    \n",
    "# btn = Button(window, text=\"Click Me\", command=clicked)\n",
    "\n",
    "# btn.grid(column=2, row=0)\n",
    "# # c\n",
    "# window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
