{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/@bedigunjit/simple-guide-to-text-classification-nlp-using-svm-and-naive-bayes-with-python-421db3a72d34\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "# import catboost\n",
    "# from catboost import CatBoostClassifier\n",
    "# import rb\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'neutral'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Corpus = pd.read_csv(r\"data/student_evaluation.csv\",encoding='latin-1')\n",
    "# Corpus.head()\n",
    "Corpus.Sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Great.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I do not know how this course is going to help...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all is Perfect.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>could be more interactive and practical with l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>More examples required to get a better grip on...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  Sentiment  Actual\n",
       "0                                             Great.        NaN       1\n",
       "1  I do not know how this course is going to help...        NaN       0\n",
       "2                                    all is Perfect.        NaN       1\n",
       "3  could be more interactive and practical with l...        NaN       0\n",
       "4  More examples required to get a better grip on...        NaN       0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(r\"data/test.csv\",encoding='latin-1')\n",
    "test.head()\n",
    "# Corpus.Sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step - a : Remove blank rows if any.\n",
    "test['comment'].dropna(inplace=True)\n",
    "\n",
    "# Step - b : Change all the text to lower case. This is required as python interprets 'dog' and 'DOG' differently\n",
    "test['comment'] = [entry.lower() for entry in test['comment']]\n",
    "\n",
    "# Step - c : Tokenization : In this each entry in the test will be broken into set of words\n",
    "test['comment']= [word_tokenize(entry) for entry in test['comment']]\n",
    "\n",
    "# Step - d : Remove Stop words, Non-Numeric and perfom Word Stemming/Lemmenting.\n",
    "# WordNetLemmatizer requires Pos tags to understand if the word is noun or verb or adjective etc. By default it is set to Noun\n",
    "tag_map = defaultdict(lambda : wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "for index,entry in enumerate(test['comment']):\n",
    "    # Declaring Empty List to store the words that follow the rules for this step\n",
    "    final_words = []\n",
    "    # Initializing WordNetLemmatizer()\n",
    "    word_Lemmatized = WordNetLemmatizer()\n",
    "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
    "    for word, tag in pos_tag(entry):\n",
    "        # Below condition is to check for Stop words and consider only alphabets\n",
    "        if word not in stopwords.words('english') and word.isalpha():\n",
    "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
    "            final_words.append(word_Final)\n",
    "    # The final processed set of words for each iteration will be stored in 'text_final'\n",
    "    test.loc[index,'test_final'] = str(final_words)\n",
    "\n",
    "# print(Final_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step - a : Remove blank rows if any.\n",
    "Corpus['comment'].dropna(inplace=True)\n",
    "\n",
    "# Step - b : Change all the text to lower case. This is required as python interprets 'dog' and 'DOG' differently\n",
    "Corpus['comment'] = [entry.lower() for entry in Corpus['comment']]\n",
    "\n",
    "# Step - c : Tokenization : In this each entry in the corpus will be broken into set of words\n",
    "Corpus['comment']= [word_tokenize(entry) for entry in Corpus['comment']]\n",
    "\n",
    "# Step - d : Remove Stop words, Non-Numeric and perfom Word Stemming/Lemmenting.\n",
    "# WordNetLemmatizer requires Pos tags to understand if the word is noun or verb or adjective etc. By default it is set to Noun\n",
    "tag_map = defaultdict(lambda : wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "for index,entry in enumerate(Corpus['comment']):\n",
    "    # Declaring Empty List to store the words that follow the rules for this step\n",
    "    Final_words = []\n",
    "    # Initializing WordNetLemmatizer()\n",
    "    word_Lemmatized = WordNetLemmatizer()\n",
    "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
    "    for word, tag in pos_tag(entry):\n",
    "        # Below condition is to check for Stop words and consider only alphabets\n",
    "        if word not in stopwords.words('english') and word.isalpha():\n",
    "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
    "            Final_words.append(word_Final)\n",
    "    # The final processed set of words for each iteration will be stored in 'text_final'\n",
    "    Corpus.loc[index,'text_final'] = str(Final_words)\n",
    "\n",
    "# print(Final_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     335\n",
       "positive    306\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(Corpus['text_final'],Corpus['Sentiment'],test_size=0.2)\n",
    "X_Test= test['test_final']\n",
    "Corpus['Sentiment'].value_counts()\n",
    "# Corpus['text_final']\n",
    "# X_Test.shape()\n",
    "# Train_X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder = LabelEncoder()\n",
    "Train_Y = Encoder.fit_transform(Train_Y)\n",
    "Test_Y = Encoder.fit_transform(Test_Y)\n",
    "# Test_X.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfidf_vect = TfidfVectorizer()\n",
    "Tfidf_vect.fit(Corpus['text_final'])\n",
    "Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
    "Test_X_Tfidf = Tfidf_vect.transform(Test_X)\n",
    "# type(Test_X_Tfidf)\n",
    "# print(Train_X_Tfidf)\n",
    "# vectorizer = CountVectorizer(ngram_range=(2,2))\n",
    "# Tfidf_vect.fit_transform(Corpus['text_final'])\n",
    "\n",
    "# print(Tfidf_vect.get_feature_names())\n",
    "\n",
    "# vectorizer = TfidfVectorizer(ngram_range=(2,2)) # You can still specify n-grams here.\n",
    "# X = vectorizer.fit_transform(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Train_X_Tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_clf_DT = Pipeline([('vect', TfidfVectorizer(ngram_range=(1,1))), \n",
    "                      ('clf', DecisionTreeClassifier()) ])\n",
    "text_clf_DT.fit(Train_X,Train_Y)\n",
    "\n",
    "predictions_DT = text_clf_DT.predict(Test_X)\n",
    "\n",
    "# print(text_clf_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix_result = confusion_matrix(Test_Y, predictions_DT)\n",
    "# print(\"Confusion matrix \\n\",confusion_matrix_result)\n",
    "print(\"\\n Classification report \\n\",classification_report(Test_Y, predictions_DT))\n",
    "print(\"\\n Decision Tree accuracy score -- > \",accuracy_score(Test_Y, predictions_DT)*100)  \n",
    "\n",
    "print(\"\\n Decision Tree precision score -- > \",precision_score(Test_Y, predictions_DT, average = 'weighted')*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the predictions with trained model and submit the predictions.\n",
    "# y_pred=model.predict_classes(X_test)\n",
    "\n",
    "# predictions_Test_NB = text_clf.predict(X_Test)\n",
    "\n",
    "predicted_svm_save = text_clf_SVM.predict(X_Test)\n",
    "\n",
    "test['Sentiment'] = predicted_svm_save\n",
    "submission = test[[\"comment\",\"Sentiment\",\"Actual\"]]\n",
    "submission.to_csv(\"data/results/SVM_submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score ->  74.4186046511628\n"
     ]
    }
   ],
   "source": [
    "# Classifier - Algorithm - SVM\n",
    "\n",
    "# fit the training dataset on the classifier\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(Train_X_Tfidf,Train_Y)\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
    "\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, Test_Y)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline model of SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score ->  78.29457364341084\n",
      "SVM precision score -- >  78.6186300673529\n"
     ]
    }
   ],
   "source": [
    "#pipeline model SVM\n",
    "text_clf_SVM= Pipeline([('vect', TfidfVectorizer(ngram_range=(1,4))), \n",
    "                      ('clf', SVC(C=1.0, kernel='linear', degree=3, gamma='auto')) ])\n",
    "# train the model\n",
    "text_clf_SVM.fit(Train_X,Train_Y)\n",
    "predicted_svm = text_clf_SVM.predict(Test_X)\n",
    "\n",
    "\n",
    "# np.mean(predicted_svm == Test_Y)\n",
    "\n",
    "# Predict the test cases\n",
    "# test_x = [input()]\n",
    "# test_x = ['Also the project helped us implement real world applications that is further helpful if we plan to do research in this field.']\n",
    "# test_x = ['Decision Support Technologies is a required course of IM course. ','no.', 'Please include Field trips.','I think an in class mini-project should be considered to be done step by step in during lectures.']\n",
    "# test_x = ['Few more application specific contents is needed. ','Good course.', 'Please include Field trips.','I think an in class mini-project should be considered to be done step by step in during lectures.']\n",
    "\n",
    "# predicted_svm = text_clf_SVM.predict(Test_Y)\n",
    "# for x in predicted_svm:\n",
    "#     print(x)\n",
    "\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(predicted_svm, Test_Y)*100)\n",
    "print(\"SVM precision score -- > \",precision_score(Test_Y, predicted_svm, average = 'weighted')*100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix \n",
      " [[51 11]\n",
      " [18 49]]\n",
      "\n",
      " Classification report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.82      0.78        62\n",
      "          1       0.82      0.73      0.77        67\n",
      "\n",
      "avg / total       0.78      0.78      0.78       129\n",
      "\n",
      "\n",
      " SVM accuracy score -- >  77.51937984496125\n",
      "\n",
      " SVM precision score -- >  77.94011908774294\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
    "confusion_matrix_result = confusion_matrix(Test_Y, predicted_svm)\n",
    "print(\"Confusion matrix \\n\",confusion_matrix_result)\n",
    "print(\"\\n Classification report \\n\",classification_report(Test_Y, predicted_svm))\n",
    "\n",
    "print(\"\\n SVM accuracy score -- > \",accuracy_score(Test_Y, predicted_svm)*100) \n",
    "print(\"\\n SVM precision score -- > \",precision_score(Test_Y, predicted_svm, average = 'weighted')*100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving test result in CSV file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the predictions with trained model and submit the predictions.\n",
    "# y_pred=model.predict_classes(X_test)\n",
    "\n",
    "# predictions_Test_NB = text_clf.predict(X_Test)\n",
    "\n",
    "predicted_svm_save = text_clf_SVM.predict(X_Test)\n",
    "\n",
    "test['Sentiment'] = predicted_svm_save\n",
    "submission = test[[\"comment\",\"Sentiment\",\"Actual\"]]\n",
    "submission.to_csv(\"data/results/SVM_submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"IS\",\"CS\", \"neutral\",\"positive\"]\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(confusion_matrix_result, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix - Text Clasiffication\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "text_format = 'd'\n",
    "thresh = confusion_matrix_result.max() / 2.\n",
    "for row, column in itertools.product(range(confusion_matrix_result.shape[0]), range(confusion_matrix_result.shape[1])):\n",
    "    plt.text(column, row, format(confusion_matrix_result[row, column], text_format),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if confusion_matrix_result[row, column] > thresh else \"black\")\n",
    "\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# parameters_svm = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "#              'tfidf__use_idf': (True, False),\n",
    "#              'clf-svm__alpha': (1e-2, 1e-3),\n",
    "# }\n",
    "# gs_clf_svm = GridSearchCV(text_clf_SVM, parameters_svm, n_jobs=-1)\n",
    "# gs_clf_svm = gs_clf_svm.fit(Train_X_Tfidf,Train_Y)\n",
    "# gs_clf_svm.best_score_\n",
    "# # gs_clf_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "# https://stackabuse.com/text-classification-with-python-and-scikit-learn/\n",
    "with open('text_classifier', 'wb') as picklefile:\n",
    "    pickle.dump(SVM,picklefile)\n",
    "\n",
    "# to load the model use the following\n",
    "with open('text_classifier', 'rb') as training_model:\n",
    "    model = pickle.load(training_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## without pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the training dataset on the classifier\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(Train_X_Tfidf,Train_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score ->  74.4186046511628\n"
     ]
    }
   ],
   "source": [
    "predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
    "\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, Test_Y)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix \n",
      " [[50 12]\n",
      " [21 46]]\n",
      "\n",
      " Classification report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.81      0.75        62\n",
      "          1       0.79      0.69      0.74        67\n",
      "\n",
      "avg / total       0.75      0.74      0.74       129\n",
      "\n",
      "\n",
      " SVM precision score -- >  75.03868439183618\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
    "confusion_matrix_result = confusion_matrix(Test_Y, predictions_SVM)\n",
    "print(\"Confusion matrix \\n\",confusion_matrix_result)\n",
    "print(\"\\n Classification report \\n\",classification_report(Test_Y, predictions_SVM))\n",
    "print(\"\\n SVM precision score -- > \",precision_score(Test_Y, predictions_SVM, average = 'weighted')*100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"suggestion\", \"neutral\",\"positive\"]\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(confusion_matrix_result, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix - Text Clasiffication\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "text_format = 'd'\n",
    "thresh = confusion_matrix_result.max() / 2.\n",
    "for row, column in itertools.product(range(confusion_matrix_result.shape[0]), range(confusion_matrix_result.shape[1])):\n",
    "    plt.text(column, row, format(confusion_matrix_result[row, column], text_format),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if confusion_matrix_result[row, column] > thresh else \"black\")\n",
    "\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score ->  48.06201550387597\n"
     ]
    }
   ],
   "source": [
    "# # Classifier - Algorithm - SVM\n",
    "# # fit the training dataset on the classifier\n",
    "# SVM = svm.SVC(C=1.0, kernel='rbf', degree=3, gamma='auto')\n",
    "# SVM.fit(Train_X_Tfidf,Train_Y)\n",
    "# # predict the labels on validation dataset\n",
    "# predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
    "# # Use accuracy_score function to get the accuracy\n",
    "# print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, Test_Y)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
